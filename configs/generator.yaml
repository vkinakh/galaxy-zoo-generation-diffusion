batch_size: 12                              # batch size for training
n_workers: 16                               # number of workers for data loading
iterations: 200000                          # number of training iterations
eval_every: 1                               # evaluate every n epochs
accumulate_grad_batches: 1                  # accumulate gradients for n batches
fp16: False                                 # use half precision training
clip_denoised: True                         # clip denoised images to [0, 1]
ema_rate: 0.999                             # exponential moving average rate

lr: 1e-4                                    # learning rate
wd: "0"                                     # weight decay

fine_tune_from:                             # path to checkpoint to fine tune from

schedule_sampler: uniform                   # sampler for schedule

dataset:                                    # dataset parameters
  image_path: <>                            # path to image directory
  label_path: <>                            # path to label directory
  size: 64                                  # image size
  n_classes: 37                             # number of classes
  n_channels: 3                             # number of channels

comment: galaxy_zoo_diffusion_generator     # comment for checkpointing
